# Finance Papers - Academic Paper Scraping & Analysis System

A comprehensive system for scraping and analyzing academic papers from top finance journals using OpenAlex API. This system automatically downloads paper metadata, stores it in a database, ranks authors, fetches working papers, and provides convenient interfaces for accessing the data.

## Supported Journals

- **JF** - Journal of Finance
- **RFS** - Review of Financial Studies
- **JFE** - Journal of Financial Economics

## Installation

### Install as a Python Package

```bash
# Clone or navigate to the project directory
cd SS\ scrape-papers

# Install in development mode (editable)
pip install -e .

# Or install normally
pip install .
```

After installation, you'll have access to these command-line tools:
- `finance-papers` - Main orchestration script
- `get-papers` - Fetch journal articles from OpenAlex
- `query-papers` - Query and rank authors from journal articles
- `get-wp` - Fetch working papers for authors
- `query-wp` - Query and display working papers
- `extract-agendas` - Extract research agendas using LLM

### Manual Setup (Alternative)

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

## Quick Start

### Using Installed Console Scripts

```bash
# Run the complete workflow (recommended)
finance-papers

# Or run individual commands
get-papers jf 2024
query-papers rank-authors top3 --250
get-wp author_list.csv 2024
query-wp rank --250
extract-agendas 250 --display
```

### Using Python Scripts Directly

```bash
# Complete workflow
python3 src/main.py

# Individual commands
python3 src/getpapers_openalex.py jf 2024
python3 src/query_openalex_db.py rank-authors top3 --250
```

## Core Scripts

### Scraping Interface (`bin/scrape`)

Unified command-line interface for scraping all supported journals:

```bash
# Scrape all journals (forthcoming articles)
./bin/scrape all

# Scrape specific journal forthcoming articles
./bin/scrape jf
./bin/scrape aer  
./bin/scrape qje
./bin/scrape rfs

# Scrape specific journal issues
./bin/scrape jf 67 1    # Volume 67, Issue 1
./bin/scrape qje 139 2  # Volume 139, Issue 2

# Show help
./bin/scrape help
```

**Features:**
- Automatic virtual environment detection and activation
- Parallel scraping for efficiency
- Comprehensive error handling and logging
- Support for both forthcoming articles and specific volume/issue combinations

### Articles Database Interface (`bin/articles`)

Interactive interface for viewing and managing scraped articles:

```bash
# Interactive menu (dmenu on macOS if available, terminal menu otherwise)
./bin/articles

# Direct commands
./bin/articles stats                    # Database statistics
./bin/articles forth                    # All forthcoming articles
./bin/articles forth jf                 # JF forthcoming articles
./bin/articles latest 10               # Latest 10 articles
./bin/articles help                     # Show all commands
```

**Menu Options:**
- Database statistics and article counts
- View forthcoming articles (all journals or specific)
- View latest articles (configurable count)
- Journal-specific article listings
- Interactive terminal and dmenu interfaces

## Individual Scrapers (`src/`)

### Forthcoming Article Scrapers
- `scrape-jf-forth.py` - Journal of Finance advance articles
- `scrape-aer-forth.py` - AER advance articles  
- `scrape-qje-forth.py` - QJE advance articles
- `scrape-rfs-forth.py` - RFS advance articles

### Volume/Issue Scrapers
- `scrape-jf.py` - JF specific volumes and issues
- `scrape-qje.py` - QJE specific volumes and issues
- `scrape-rfs.py` - RFS specific volumes and issues
- `scrape-aer.py` - AER specific volumes and issues

### Database Management
- `save_db.py` - Database operations and article storage
- `print_db` - Direct database query utility

## Features

### Data Storage
- **SQLite Database**: Structured storage in `out/data/articles.db`
- **CSV Export**: Articles saved to `out/data/articles_[journal].csv`
- **Duplicate Detection**: Automatic deduplication based on DOI/URL and titles
- **Metadata**: Complete article information (title, authors, abstract, publication date, volume, issue, links)

### Advanced Scraping
- **Multiple Strategies**: Each scraper uses multiple approaches to handle anti-bot measures
- **RSS Fallbacks**: Automatic fallback to RSS feeds when direct scraping is blocked
- **Realistic Browser Simulation**: Complete headers and session management
- **Rate Limiting**: Respectful delays and retry mechanisms

### User Interfaces
- **dmenu Integration**: Native macOS menu support with dmenu-mac
- **Terminal Menus**: Full-featured terminal interface as fallback
- **Raycast Integration**: Pre-configured for Raycast launcher on macOS

## Project Structure

```
scrape-papers/
├── bin/                    # Command-line interfaces
│   ├── scrape             # Main scraping interface
│   ├── articles           # Article database interface
│   └── print_db          # Database query utility
├── src/                    # Individual scraper scripts
│   ├── scrape-*-forth.py  # Forthcoming article scrapers
│   ├── scrape-*.py        # Volume/issue scrapers
│   ├── save_db.py         # Database operations
│   └── test_db_path.py    # Database testing
├── out/data/              # Output directory
│   ├── articles.db        # SQLite database
│   └── articles_*.csv     # CSV exports
├── requirements.txt       # Python dependencies
└── README.md             # This file
```

## Dependencies

- **requests** - HTTP requests and session management
- **beautifulsoup4** - HTML parsing and extraction
- **sqlite3** - Database operations (built-in)
- **csv** - CSV file operations (built-in)

## Usage Examples

### Daily Workflow
```bash
# Morning: Check for new articles
./bin/scrape all

# View what's new
./bin/articles forth

# Check specific journal
./bin/articles forth rfs
```

### Research Workflow
```bash
# Get latest papers for review
./bin/articles latest 20

# Check JF forthcoming for finance research
./bin/articles forth jf

# Get database statistics
./bin/articles stats
```

### Historical Data Collection
```bash
# Scrape specific volumes
./bin/scrape qje 139 1
./bin/scrape qje 139 2
./bin/scrape qje 139 3

# Check results
./bin/articles stats
```

## Technical Notes

- **Anti-Bot Measures**: Academic publishers use sophisticated blocking. Scrapers include multiple fallback strategies.
- **Rate Limiting**: Respectful delays prevent overwhelming servers
- **Data Integrity**: Comprehensive duplicate detection and validation
- **Cross-Platform**: Works on macOS, Linux, and Windows (with appropriate dmenu alternatives)

## Troubleshooting

- **Virtual Environment**: Ensure `.venv` or `venv` directory exists with required packages
- **Database Issues**: Database is created automatically in `out/data/`
- **dmenu Problems**: Falls back to terminal menus automatically
- **Scraping Blocked**: RSS feeds provide fallback access when direct scraping fails